
本文试图讲清楚工具调用的发展过程，重点聚焦于其中具体的技术实现，帮助我和有需要的人理解这个越来越常见的概念。

## 什么是工具调用？
工具调用，指的是大模型在处理任务时，能够识别出任务的需求，并主动调用各种外部工具来获取信息、执行操作或者完成推理，再将信息整合进最终回答中。

外部工具包括计算器、搜索引擎、代码解释器、数据库接口或者其它自定义API等，有了能调用工具的能力，大模型不再局限于预训练和微调学到的静态知识，也有能力向智能体（Agent）的方向发展：一个能够自主感知环境、规划行动、调用工具并持续学习进步的AI工具。

在人工智能不断迈向实用化与自主化的进程中，“工具调用”（Tool Calling）已然成为大语言模型突破自身局限的关键能力。

## 一、发展起点：GPT3
2020年，大家熟知的ChatGPT还不见踪影，大语言模型发展正处于萌芽阶段。OpenAI发布了GPT3并对小部分开发者开放了API，开发者在实际操作中发现，可以通过在提示词中告诉大模型“你具有工具调用能力，可以调用哪些函数”，它就能够在某些回答中主动要求调用某个工具。

比如我向大模型提问：“今天天气怎么样？”
大模型会回复：“我需要调用天气查询API进行信息搜索。”

这正是工具调用的雏形，OpenAI的函数调用机制也成为了工具调用技术的起点。

### 技术实现
当时的开发者是怎么让大模型知道什么时候该调用工具、什么时候该直接回答的呢？

答案是靠提示工程（Prompt Engineering）和外部规则匹配。

GPT-3是一个纯文本生成模型，它并没有思考理解的能力，它无法理解什么是API，也不知道怎么调用工具，但是你可以提示它，帮助它学会如何做。

开发者一般通过在系统提示（System Prompt）中给模型设定好扮演的角色和对应的行为准则，比如（以下为模拟2020年的简略版本）：

```text
你是一个智能助手，可以使用以下工具： 
- weather(city): 查询某城市的天气 

当用户的问题需要外部信息时，请严格按以下格式回复： 
{"tool": "weather", "params": {"city": "城市名"}} 

如果问题可以直接回答，请直接给出自然语言答案。
```

这样当用户询问：“今天北京天气怎么样”时，模型就会输出：

```json
{"tool": "weather", "params": {"city": "北京"}}
```

在模型按照规则进行输出后，关键一步在于开发者使用外部程序进行判断：

例如可以写：
- 如果输出为合法json格式且包含“tool”字段→调用对应工具
- 否则→直接进行回答

这样，当外部程序检测到json输出后，就会去调用对应的工具，在拿到结果后将结果附上新的提示词喂给大模型，比如：

```text
工具返回结果：北京今天多云，无雨。

请用自然语言对用户进行回复。
```

最后，大模型就会回答正确的答案。

### 局限性
从上面的例子中，大家能感受到这个阶段的工具调用具有很大局限性：
1. 首先模型仅能调用单一工具：
	但凡问题复杂一些，例如“在周杰伦生日那天北京天气如何”，这样大模型同时需要查询“周杰伦的生日”和“对应日期北京的天气”两个问题，但是大模型不懂工具间的关联与衔接，此时就无法实现。
2. 其次开发者必须写好明确的工作流程：
	这个阶段的大模型并没有判断能力，无论是工具匹配还是还是流程规划都需要开发者提前写死，但凡出现提示词中没有覆盖到的场景，大模型也会宕机。
3. 最后是非常依赖用户的参数输入：
	例如上面的例子，如果用户在提问中没有明确说明需要查询天气的城市，大模型也没法编一个参数填进去，任务也无法完成。

### 一句话总结

> OpenAI 早期的函数调用 = 模型生成结构化指令（JSON）→ 外部程序识别并执行工具 → 返回结果给模型 → 模型回答用户

## 二、主动出击：WebGPT
然而，仅靠静态知识远远不够。当用户问出‘今天发生了什么大事？’，GPT-3 只能沉默——于是，能主动上网的 WebGPT 应运而生。

WebGPT是OpenAI在2021年底发布的一项重要研究，它基于GPT-3微调所得，代表了大模型从单纯的文本生成向主动工具调用能力的重要突破。

WebGPT的核心进步是使大模型学会了主动使用外部工具——网络浏览器进行“外部知识引入”。

WebGPT在收到用户的问题后，可以像人类一样使用互联网搜索相关信息、生成带有引用链接的回复。目前市面上绝大部分AI应用都已将联网搜索作为最基础的功能。

### 技术实现

为什么WebGPT能够知道合适该调用工具、进行联网搜索？

关键在于基于人类反馈的强化学习（RLHF）机制。

具体实现上可以分为两步：

1. 首先用监督学习（SFT)的方法对大模型进行微调：
	给模型提供大量的人工标注的“问答→浏览器操作序列”的训练数据，比如：
	
```text
Q：谁赢得了 2021 年图灵奖？ 
A：
search("2021 Turing Award winner") 
click(0) // 点第一个结果 
quote("Jack Dongarra was awarded the 2021 ACM A.M. Turing Award.")
```

2. 再用RLHF进行训练：
	通过人工的方式对不同操作序列下生成的结果进行一系列指标评估并打分，用这些数据训练一个奖励模型，鼓励大模型向分数更高的生成方式靠齐，让它真正学会更高效准确的搜索方法。

在实际对话过程中，模型的推理过程如下图所示，总结起来就是“搜索→点击→引用”。

![[Pasted image 20251216161145.png]]

### 局限性
尽管进步很大，WebGPT仍存在一定局限性：
1. 首先是只能使用部分公开网页：
	因为此时不具备写的能力，涉及要登录账号、填写表单才能获取的信息就无法涉及。
2. 其次是很依赖搜索引擎质量：
	如果搜不到好结果，大模型也无能为力，可能还是会给出错误答案。
3. 最后是计算成本提高了：
	一次问答中会涉及到多次模型调用和网页加载。

正因如此，研究者开始探索让模型真正‘理解’何时该调用工具——而不仅仅是模仿格式。

### 一句话总结

> WebGPT = 大模型 + 受限浏览器 + 基于人类反馈的强化学习

## 三、思行合一：ReAct
WebGPT进行完信息查询后不会进行推理整合，难以完成复杂任务，因此能边思考边行动的ReAct（Reasoning + Acting）出现了。

在大模型迈向更智能、更强大的智能体过程中，ReAct标志着一个关键转折点，成为之后智能体开发的标准范式。

2022年，ReAct由普林斯顿大学和谷歌联合提出，首次系统性的将思维链（Chain of Thought）与外部工具调用融合进一个大框架中，让模型不仅能想得明白，也能做得明白。

不同于早期纯推理或者纯行动的方法，ReAct在输出中交替生成“Thought（思考）”、“Action（行动）”和“Observation（观察）”步骤，构建了一个闭环的智能体工作流。

### 技术实现

ReAct是如何教会模型这样思考的呢？

开发者采用的方法是提示工程 + 少样本示例（Few-shot Prompting）。

开发者提供给大模型一个包含ReAct格式的提示模板，例如：

```text
## 你可以使用以下工具：

- check_flight_route(origin, dest)：返回该航班是国内航班还是国际航班。
- get_entry_requirements(country, citizenship)：返回前往该国家所需的护照/签证要求。

## 请使用以下格式：  

Thought: ...  
Action: 工具名称  
Action Input: { ... }  
Observation: ...  
...（根据需要重复上述步骤）  
Answer: ...

## 示例：  

Question：从东京飞往首尔需要护照吗？  
Thought: 我需要先确认这是否是一趟国际航班。  
Action: check_flight_route  
Action Input: {"origin": "Tokyo", "destination": "Seoul"}  
Observation: 国际航班。  
Thought: 那么我应该查询韩国的入境要求。  
Action: get_entry_requirements  
Action Input: {"country": "South Korea", "citizenship": "Japan"}  
Observation: 日本公民需要护照。  
Answer: 是的，你需要护照。
```

通过少样本示例，大模型可以有效地学习到如何在新问题中也应用类似的闭环工作流。

### 局限性

尽管ReAct在工具调用方面进步巨大，但仍存在提升空间：

1. 缺乏全局规划能力：
ReAct采用的方法是走一步看一步，缺乏对长程任务的规划能力，容易在复杂任务中陷入局部最优甚至死循环；

2. 依赖高质量工具集：
ReAct依赖预先定义好的工具名称和输入格式，如果工具集设置不够全面或工具返回出错，任务依然会失败。

### 一句话总结

> ReAct = “思考 → 行动 → 观察 → 再思考”循环

## 四、原生支持：原生工具调用

尽管 ReAct 通过精心设计的提示模板，成功让大语言模型在“思考”与“行动”之间动态切换，展现出初步的智能体行为，但其本质仍是一种基于文本约定的模拟机制——工具调用以自然语言形式嵌入生成内容，需依赖后处理正则或 JSON 解析，极易因格式偏差而失效。

因此，为了能让大模型能结构化地请求调用工具，而不是靠文本模仿，各家AI公司纷纷让自家模型原生支持工具调用。

例如，2023 年 6 月，OpenAI 在其Chat Completions API中正式新增Function Calling功能；2024年，Claude 3.5也支持原生工具调用等等。下面将以OpenAI为例进行说明。

在支持原生工具调用之后，大模型不再通过文本的方式去说出要调哪个工具，而是直接通过 API 响应中的专用字段，返回一个结构化的函数调用请求。

这个请求会由后端进行严格校验格式，保证工具名称合法、参数符合预定义、不会出现内容错误或幻觉调用。

### 技术实现

我们用一个例子来进行说明：

用户进行提问：“今天北京天气怎么样？”

首先，平台会对可用工具集进行一个结构化定义：
```json
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "获取指定城市的当前天气",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {"type": "string", "description": "城市名称，如 '北京'"},
                },
                "required": ["city"]
            }
        }
    }
]
```

在每次对话中，平台会调用大模型的API，发送你的问题：

```json
{
  "model": "gpt-3.5-turbo",
  "messages": [{"role": "user", "content": "今天北京天气怎么样？"}],
  "tools": tools,               // ← 把上面的工具定义传进去
  "tool_choice": "auto"         // 让模型自己决定是否调用
}
```

之后，大模型会返回给平台一个“函数调用”响应，注意其中`content`为`null`,但是新增了`tool_calls`字段：

```json
{
  "message": {
    "role": "assistant",
    "content": null,
    "tool_calls": [
      {
        "id": "call_abc123",
        "type": "function",
        "function": {
          "name": "get_weather",
          "arguments": "{\"city\": \"北京\"}"
        }
      }
    ]
  }
}
```

平台解析模型返回的json数据，根据需求调用对应函数，并把结果作为“工具信息”发回给模型：

```python
weather_result = get_weather("北京")  # 返回: "多云，18°C"
```
```json
{
  "role": "tool",
  "tool_call_id": "call_abc123",   // 匹配相同的 id
  "content": "多云，18°C"
}
```

最后，你将用户原始问题 + 工具调用请求 + 工具结果一同传给模型，模型输出自然语言回答，你将回答传回给用户。

```json
{
  "model": "gpt-3.5-turbo",
  "messages": [
    {"role": "user", "content": "今天北京天气怎么样？"},
    {
      "role": "assistant",
      "tool_calls": [ ... ]  
    },
    {
      "role": "tool",
      "tool_call_id": "call_abc123",
      "content": "多云，18°C"
    }
  ]
}
```

从上面例子可以看出，原生工具调用大大提升了稳定性：
1. 由文本生成修改为结构化数据生成，出错概率大大降低；
2. 开发者无需再自己写代码解析文本，平台后端会统一校验；
3. 由于底层技术的改变，现在采用的是受限解码（Constrained Decoding）的技术，大模型只能生成你在工具列表中定义过的工具名字，出现幻觉可能性大大降低。

### 一句话总结
> OpenAI Function Calling = 原生、可靠、结构化的工具调用机制

## 五、高效编排：LangChain

原生工具调用解决了“模型如何可靠地请求工具”的问题，而 LangChain 等框架则回答了“开发者如何高效地构建和编排基于工具调用的智能体应用”的问题。

如果说原生工具调用是引擎，那么LangChain就是围绕它打造的整车系统，极大降低了智能体应用的开发门槛。

LangChain 是一个开源的开发框架，如果说 ReAct 提出了“智能体应边思考边行动”的蓝图，那么 LangChain 就是将这张蓝图变成了一套标准化的乐高积木——工具、记忆、Agent 策略各成模块，开发者只需按需组合，即可搭建出功能完整的 AI 智能体。

### 技术实现

LangChain把工具调用拆分为了四个关键角色：
- Tool：工具，封装外部功能；
- Agent：智能体，负责决策；
- AgentExecutor：执行器，管理Agent与Tool之间的循环交互；
- Memory：记忆，保留长短期状态。

我们还是举一个例子：

用户的问题是：“我上周提到的项目进展如何？顺便查一下北京明天的天气。”

现在开始配置工具：
```python
from langchain.tools import tool

@tool
def get_weather(city: str) -> str:
    # 调用真实天气 API
    return 真实天气情况
```

选择Agent类型：
```python
from langchain.agents import create_react_agent
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(model="gpt-4-turbo")
agent = create_react_agent(llm, tools=[get_weather], prompt=react_prompt) # 最常用的ReAct Agent
```

配置Memory：
```python
from langchain.memory import ConversationBufferMemory

memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True
)
```

最后，运行AgentExecutor：
```python
from langchain.agents import AgentExecutor

executor = AgentExecutor(
    agent=agent,
    tools=[get_weather],
    memory=memory,
    verbose=True  # 打印每一步 Thought/Action
)

response = executor.invoke({"input": "我上周提到的项目进展如何？顺便查一下北京明天的天气。"})
```

当`executor.invoke()`被调用时，LangChain会自动进行“推理+工具调用+整合记忆+工具结果”。

从上面这个例子可以看出，个人开发者只需要关心工具定义、Agent选择、记忆管理，其他重复造过的轮子通过Python包就能直接复用，效率大大提高。

### 一句话总结
> LangChain = 封装模块 + 高效搭建智能体

## 六、平台时代：智能体平台

随着智能体应用场景日益复杂，从单任务问答走向多角色协作、从静态工具调用走向动态环境交互、从一次性响应走向持续学习与记忆，仅靠如LangChain般代码层面的模块组合已显不足。

2025 年，行业重心正从“构建智能体”转向“**运行智能体生态**”。

大量的智能体平台开始涌现。它们不再只是开发库，而是集成了工具市场、记忆中枢、MCP、安全沙箱、自动评估与迭代机制的一体化操作系统。

常见的智能体平台包括OpenAI Assistants API、LangChain + LangGraph、LlamaIndex、Dify、Coze等等。

### 技术实现

如今的智能体平台，工具调用的操作已大幅度简化，开发者所有的操作都可以在前端界面通过拖拉拽和低代码的方式实现，大量的调度、校验、执行都由平台自动完成。

具体来说：
- 可以直接在可视化界面中填写声明工具接口；
- 记忆、多轮对话、权限控制等功能点击即用；
- 通过工具市场直接复用他人工具等等。

比如 Coze 允许你在网页上拖拽一个‘天气查询’组件，绑定 API 后直接发布为 Bot；而 OpenAI Assistants 则内置了文件检索与代码解释器，无需写一行代码。

### 一句话总结

> 智能体平台工具调用 = 傻瓜式拖拉拽 + 低代码


## 结语


从 GPT-3 时代依赖提示工程的“伪调用”，到 WebGPT 主动联网搜索的初步探索；

从 ReAct 构建“思考—行动—观察”的智能闭环，到原生工具调用实现结构化、高可靠性的函数交互；

再到 LangChain 等框架将智能体开发模块化、标准化，直至今日各类智能体平台以低代码、可视化的方式降低使用门槛。

工具调用的发展历程，本质上是大模型从“被动回答者”向“主动执行者”演进的缩影。

未来，随着工具生态的丰富、记忆机制的深化以及多智能体协同架构的成熟，我们或将见证真正具备环境感知、目标规划与自我迭代能力的通用智能体诞生。

而工具调用，正是这条通往 AGI 之路上不可或缺的桥梁。